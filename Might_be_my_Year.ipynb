{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9aZeDngQFwlk12lSXSxtG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimMiller-0/Might-be-my-Year/blob/main/Might_be_my_Year.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a notebook for retreiving Fantasy Football Data from ESPN for analysis and predictive capabilities"
      ],
      "metadata": {
        "id": "z3kfLMqUCIae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data"
      ],
      "metadata": {
        "id": "16MbXDTu05eO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AFYH1buE0yXl"
      },
      "outputs": [],
      "source": [
        "# Install necessary SDKs\n",
        "\n",
        "!pip install espn-api\n",
        "!pip install google-cloud-secret-manager\n",
        "!pip install google-cloud-bigquery\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "7AyX4ppD6ZT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from espn_api.football import League\n",
        "from google.cloud import secretmanager\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os"
      ],
      "metadata": {
        "id": "5-Ti3jn76GhW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "League Variables & Access Tokens for ESPN API"
      ],
      "metadata": {
        "id": "2bIPDfui5_1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You will need to get your league ID and ESPN S2 and SWID\n",
        "# See https://github.com/cwendt94/espn-api/wiki/Football-Intro for details\n",
        "# Recommended: Store SWID and ESPN S2 in a secrets manager, like gcp secrets manager: https://cloud.google.com/security/products/secret-manager\n",
        "\n",
        "league_id = 1054374 # => set to league ID that you want to pull data from\n",
        "season=2023 # => set to year you want to pull data from\n",
        "url=f'https://lm-api-reads.fantasy.espn.com/apis/v3/games/ffl/seasons/{season}/segments/0/leagues/{league_id}?scoringPeriodId=17&view=mBoxscore&view=m' # => url of ESPN API. Note: this has changed over the years, navigate to the site and inspect network calls to get current endpoint\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#Create a Client for secrets manager\n",
        "client = secretmanager.SecretManagerServiceClient()\n",
        "project_id = 'might-be-my-year' # => GCP Project ID where secrets manager is enabled\n",
        "secret_espn_s2 = 'espn_s2' # name of secret in GCP secrets manager for espn_s2\n",
        "secret_swid = 'swid' # name of secret in GCP secrets manager for swid\n",
        "\n",
        "# Forge the paths to the latest version of the secrets with a F-string:\n",
        "resource_name_espn_s2 = f\"projects/{project_id}/secrets/{secret_espn_s2}/versions/latest\"\n",
        "resource_name_swid = f\"projects/{project_id}/secrets/{secret_swid}/versions/latest\"\n",
        "\n",
        "# Load up the secrets to a variable at runtime:\n",
        "response_espn_s2 = client.access_secret_version(name=resource_name_espn_s2)\n",
        "response_swid = client.access_secret_version(name=resource_name_swid)\n",
        "\n",
        "espn_s2 = response_espn_s2.payload.data.decode(\"UTF-8\")\n",
        "swid = response_swid.payload.data.decode(\"UTF-8\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ItuWEaB354yR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data From ESPN API"
      ],
      "metadata": {
        "id": "YePLEaBR6cgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(url, cookies={'swid': swid, 'espn_s2': espn_s2})\n",
        "if r.status_code == 200:\n",
        "\n",
        "  data = r.json()\n",
        "  data\n",
        "\n",
        "# Save the data to a JSON file\n",
        "  with open('data.json', 'w') as f:\n",
        "        json.dump(data, f, indent=0)  # Use indent for pretty printing\n",
        "  print('JSON file saved successfully.')\n",
        "else:\n",
        "  print('Request failed with status code:', r.status_code)\n",
        "\n",
        "# Read the JSON file\n",
        "with open('data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "data\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fcZfj0Zv6hdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data in a schema that makes sense because ESPN is crazy."
      ],
      "metadata": {
        "id": "pa59k0F_QBZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test to make sure pandas can put the json into a dataframe\n",
        "df = pd.json_normalize(data, record_path=['teams'])\n",
        "df"
      ],
      "metadata": {
        "id": "_twQzSOJP_93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Draft Details\n",
        "\n",
        "draft_url= f'https://lm-api-reads.fantasy.espn.com/apis/v3/games/ffl/seasons/{season}/segments/0/leagues/{league_id}?view=mDraftDetail&view=mSettings&view=mTeam&view=modular&view=mNav'\n",
        "\n",
        "r = requests.get(draft_url, cookies={'swid': swid, 'espn_s2': espn_s2})\n",
        "if r.status_code == 200:\n",
        "\n",
        "  draft_data = r.json()\n",
        "  draft_data\n",
        "\n",
        "# Save the data to a JSON file\n",
        "  with open('draft_data.json', 'w') as f:\n",
        "        json.dump(draft_data, f, indent=0)  # Use indent for pretty printing\n",
        "  print('JSON file saved successfully.')\n",
        "else:\n",
        "  print('Request failed with status code:', r.status_code)\n",
        "\n",
        "  # Read the JSON file\n",
        "with open('draft_data.json', 'r') as f:\n",
        "    draft_data = json.load(f)\n",
        "\n",
        "draft_picks_df = pd.json_normalize(draft_data['draftDetail'], record_path=['picks'])\n",
        "draft_members_df = pd.json_normalize(draft_data, record_path=['members'])\n",
        "draft_settings_df = pd.json_normalize(draft_data['settings'])\n",
        "draft_status_df = pd.json_normalize(draft_data['status'])\n",
        "draft_teams_df = pd.json_normalize(draft_data, record_path=['teams'])\n",
        "\n",
        "# test to make sure dataframes are working\n",
        "draft_teams_df\n"
      ],
      "metadata": {
        "id": "9ty2xRL2SybJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data in BigQuery - This makes is easier to manually slice and dice"
      ],
      "metadata": {
        "id": "XSkBBVBOp5f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pyarrow as pa\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# set project id again\n",
        "project_id = 'might-be-my-year'  # Replace with your actual project ID\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "# TODO(developer): Set dataset_id to the ID of the dataset to create.\n",
        "dataset_id = \"{}.fantasy_football\".format(bq_client.project)\n",
        "\n",
        "# Construct a full Dataset object to send to the API.\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# TODO(developer): Specify the geographic location where the dataset should reside.\n",
        "dataset.location = \"US\"\n",
        "\n",
        "# Check if the dataset exists\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)  # Make an API request.\n",
        "    print(f\"Dataset {dataset_id} already exists.\")\n",
        "except NotFound:\n",
        "    print(f\"Dataset {dataset_id} does not exist. Creating...\")\n",
        "# Send the dataset to the API for creation, with an explicit timeout.\n",
        "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
        "# exists within the project.\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
        "    print(\"Created dataset {}.{}\".format(bq_client.project, dataset.dataset_id))\n",
        "\n",
        "# create lists of all dataframes with coooresponding table names\n",
        "all_dfs = [draft_picks_df, draft_members_df, draft_settings_df, draft_status_df, draft_teams_df]\n",
        "table_names = ['draft_picks', 'draft_members', 'draft_settings', 'draft_status', 'draft_teams']\n",
        "\n",
        "for df, table_name in zip(all_dfs, table_names):\n",
        "\n",
        "# Replace periods in column names with underscores\n",
        "  df.columns = df.columns.str.replace('.', '_')  # Replace '.' with '_' in column names because thats what BQ needs\n",
        "# Convert the DataFrame to a Parquet file\n",
        "  table = pa.Table.from_pandas(df)\n",
        "  pq.write_table(table, f'{table_name}.parquet')\n",
        "\n",
        "# TODO(developer): Set table_id to the ID of the table to create.\n",
        "  table_id = f'{dataset_id}.{table_name}_{season}'\n",
        "\n",
        "  job_config = bigquery.LoadJobConfig(\n",
        "      autodetect=True, source_format=bigquery.SourceFormat.PARQUET\n",
        "  )\n",
        "\n",
        "# open parquet file -> load the table from parquet file into bq table\n",
        "  with open(f'{table_name}.parquet', \"rb\") as source_file:\n",
        "      job = bq_client.load_table_from_file(\n",
        "          source_file, table_id, job_config=job_config\n",
        "      )\n",
        "\n",
        "# Wait for the job to complete\n",
        "  job.result()\n",
        "\n",
        "  print(\"Loaded {} rows and {} columns to {}\".format(job.output_rows, len(df.columns), table_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TJdAsHVp5KJ",
        "outputId": "f9f04f75-3305-4fe2-dd42-7315b7b2801f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset might-be-my-year.fantasy_football already exists.\n",
            "Loaded 180 rows and 14 columns to might-be-my-year.fantasy_football.draft_picks_2023\n",
            "Loaded 12 rows and 7 columns to might-be-my-year.fantasy_football.draft_members_2023\n",
            "Loaded 1 rows and 131 columns to might-be-my-year.fantasy_football.draft_settings_2023\n",
            "Loaded 1 rows and 56 columns to might-be-my-year.fantasy_football.draft_status_2023\n",
            "Loaded 12 rows and 125 columns to might-be-my-year.fantasy_football.draft_teams_2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Data\n",
        "\n",
        "Goal: Plot \"Winners\" and \"Losers\" based off of draft day auction price vs. production.\n",
        "\n",
        "should be somthing like avg auction value vs price paid for on draft day vs inferred auction value based on end of year performance\n",
        "\n",
        "plot 1: avg auction value vs price paid for on draft day. + difference shows league values that player/position more, - difference league values that player/position less\n",
        "\n",
        "plot 2: avg auction value vs inferred auction value based on end of the year performance. + difference = player outperfomed expectations, - difference = player underperformed expectations\n",
        "\n",
        "Plot 3: differnece in plot 1 vs difference in plot 2. quadrant plot: q1 =  players who under performed and the league overvalued. q2 = players who out performed and the league over valued. q3 = players who outperformed and the league undervalued. q4 =  players that underperformed and the league undervalued\n"
      ],
      "metadata": {
        "id": "44cq2X_pHGnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "TtDLy-p9J2Kr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}